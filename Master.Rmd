---
title: "Road Safety in UK 2016"
author: Yang Dai
output: html_notebook
---

# Get the data
The data I'm using here is [road safety data](https://data.gov.uk/dataset/road-accidents-safety-data) in UK 2016. There are 3 datasets: Accidents, Vehicle, Casualty. As it's easy to understand, an accident is mostly likely involve more than 1 vehicle, and it's likely to have multiple casualties from different vehicles. So Vehicle and Casualty are linked with Accidents by Accident_Index, Casualty and Vehicle are linked by Vehicle_Reference.

I also used [UK population data](https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/timeseries/gbpop/pop) in my analysis.

I got the UK shapefiles from [here](http://geoportal.statistics.gov.uk/datasets/local-authority-districts-december-2016-full-clipped-boundaries-in-great-britain).

```{r message=FALSE, warning=FALSE}
if (!file.exists("./data/dftRoadSafety_Accidents_2016.csv")) download.file("https://github.com/daiyang94815/Road-Safety-UK-2016/raw/master/data/dftRoadSafety_Accidents_2016.csv", destfile = "./data/dftRoadSafety_Accidents_2016.csv", mode = "wb")

if (!file.exists("./data/Cas.csv")) download.file("https://github.com/daiyang94815/Road-Safety-UK-2016/raw/master/data/Cas.csv", destfile = "./data/Cas.csv", mode = "wb")

if (!file.exists("./data/Veh.csv")) download.file("https://github.com/daiyang94815/Road-Safety-UK-2016/raw/master/data/Veh.csv", destfile = "./data/Veh.csv", mode = "wb")

if (!file.exists("./data/Road Accident Safety Data Guide.xls")) download.file("https://github.com/daiyang94815/Road-Safety-UK-2016/raw/master/data/Road%20Accident%20Safety%20Data%20Guide.xls", destfile = "./data/Road Accident Safety Data Guide.xls", mode = "wb")

if (!file.exists("./data/ukmidyearpopest2016.xls")) download.file("https://github.com/daiyang94815/Road-Safety-UK-2016/raw/master/data/ukmidyearpopest2016.xls", destfile = "./data/ukmidyearpopest2016.xls", mode = "wb")
```

```{r message=FALSE, warning=FALSE}
library(readr)
accidents <- read_csv("./data/dftRoadSafety_Accidents_2016.csv")
vehicle <- read_csv("./data/Veh.csv")
# casualty <- read_csv("./data/Cas.csv")

library(readxl)
guide_lad <- read_xls("./data/Road Accident Safety Data Guide.xls", sheet = 6)
pop <- read_excel("./data/ukmidyearpopest2016.xls", sheet =5,skip=4)
```

Duplicate the dataset for different uses:
```{r}
accidents_EDA <- accidents
accidents_map <- accidents
accidents_reg <- accidents
vehicle_reg <- vehicle
```

## Explore the distribution of where accidents took place (rural/urban) (dichotomous data)
```{r}
#distribution of its values:
table(accidents_EDA$Urban_or_Rural_Area)
```
According to the guide, 1=Urban, 2=Rural, 3=Unallocated. So let's drop the unallocated incidents and label the codes.
```{r}
accidents_EDA[accidents_EDA$Urban_or_Rural_Area==3,]$Urban_or_Rural_Area <- NA
accidents_EDA$Urban_or_Rural_Area=factor(accidents_EDA$Urban_or_Rural_Area,
                                     labels=c('Urban','Rural'))
```
Re-test:
```{r}
table(accidents_EDA$Urban_or_Rural_Area)
prop.table(table(accidents_EDA$Urban_or_Rural_Area))
```
Apparently, accidents happen more often in urban areas.

### Central measurement and dispersion
Make a function for getting mode:
```{r}
getMode=function(aColumn){
  freqTable=table(aColumn)
  maxFrequency=max(freqTable)
  names(freqTable[freqTable==maxFrequency])
}
```
Get the mode to see where accidents_EDA took place more often.
```{r}
getMode(accidents_EDA$Urban_or_Rural_Area)
```

##Explore the distribution of accident severity (ordinal categorical variable)
Label the code:
```{r}
# getting original levels:
levelCat <- names(table(accidents_EDA$Accident_Severity))

# reordering original levels:
levelCat <- rev(levelCat)

# format this into an ordinal variable:
accidents_EDA$Accident_Severity=factor(accidents_EDA$Accident_Severity,
                             levels = levelCat,
                             labels=c('Slight','Serious','Fatal'),ordered=T)
```
Then see the distribution:
```{r}
table(accidents_EDA$Accident_Severity)
```

### Central Value
To see which severity happens more often:
```{r}
# get the mode
getMode(accidents_EDA$Accident_Severity)
```
```{r}
library(DescTools)
# get the median
Median(accidents_EDA$Accident_Severity, na.rm = T) 
```
```{r}
cumsum(prop.table(table(accidents_EDA$Accident_Severity)))
```
Most of the accidents happened are slight.

### Dispersion
```{r}
Gini(table(accidents_EDA$Accident_Severity))
```
Gini tells that there is some concentration. The plot should help us get a better idea:
```{r message=FALSE, warning=FALSE}
library(tidyverse)
accidents_EDA[!is.na(accidents_EDA$Accident_Severity),] %>%
  ggplot(aes(Accident_Severity)) + geom_bar()
```

## Explore the distribution of month and hour (ordinal categorical variable)
Now I want to know how accidents happen in the year and in a day.  
Here I create 2 new variables of hour and month.
```{r}
library(lubridate)
accidents_EDA_T <- transmute(accidents_EDA, 
                             hour = hour(accidents_EDA$Time),
                             month = month(accidents_EDA$Date))
```

### Central Value:
Let's see in what hour and what month did accidents happen most:
```{r}
# Applying our function:
getMode(accidents_EDA_T$hour)
```
```{r}
getMode(accidents_EDA_T$month)
```

### Dispersion
Let's see the Gini's:
```{r}
Gini(table(accidents_EDA_T$month))
```
```{r}
Gini(table(accidents_EDA_T$hour))
```
Gini tells that accidents_EDA happened roughly equally through 12 months, but have some concentration during a day. The plot should help us get a better idea:
```{r}
data <- accidents_EDA_T[!is.na(accidents_EDA_T$month),]
c <- ggplot(data,aes(factor(month)))
c + geom_bar()
```

```{r}
data <- accidents_EDA_T[!is.na(accidents_EDA_T$hour),]
c <- ggplot(data,aes(factor(hour)))
c + geom_bar()
```
We can see most accidents happened during morning peak (8am) and afternoon peak (3pm-6pm).

## Explore number of vehicles involved in accidents (counts)
### Centrality
Now I want to know usually how many vehicles are involved in an accident:
```{r}
summary(accidents_EDA$Number_of_Vehicles)
```
We can see most accidents involve 2 vehicles, but there is 1 major accidents involving 16 vehicles!

### Skewness
```{r}
library(moments)
skewness(accidents_EDA$Number_of_Vehicles,na.rm=T)
```
Positive value indicates the distribution is right-skewed, meaning most accidents involve a few vehicles.

### Kurtosis
```{r}
kurtosis(accidents_EDA$Number_of_Vehicles,na.rm=T)
```
Positive value indicates it's more concentrated than a normal distribution (the mode is very significant.)

```{r}
accidents_EDA %>%
  ggplot(aes(factor(Number_of_Vehicles))) + geom_bar() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(x='Number of Vehicles', title='Number of Vehicles involved in an accident')
```
We can see most accidents involved 2 vehicles.

## Explore the relationship between Road Surface Conditions and Accident Severity (Categorical - Categorical)
Now I want to know what is the relationship between road surface conditions and accident severity.
Let's label the road surface conditions first.
```{r}
accidents_EDA$Road_Surface_Conditions=factor(factor(accidents_EDA$Road_Surface_Conditions),
                             labels=c('Data missing or out of range','Dry','Wet or damp','Snow',
                                      'Frost or ice','Flood over 3cm. deep'))
```
Then explore the distribution:
```{r}
table(accidents_EDA$Road_Surface_Conditions)
```
better to see with a contingency table (crosstab):
```{r}
table(accidents_EDA$Road_Surface_Conditions,accidents_EDA$Accident_Severity)
```
```{r}
library(gmodels)
CrossTable(accidents_EDA$Road_Surface_Conditions,accidents_EDA$Accident_Severity,prop.t=F, prop.r=F, prop.c=F,prop.chisq=F)
```
ignore data that is missing or out of range in Road_Surface_Conditions:
```{r}
levels(accidents_EDA$Road_Surface_Conditions)[1]=NA
CrossTable(accidents_EDA$Road_Surface_Conditions,accidents_EDA$Accident_Severity,prop.t=T, prop.r=F, prop.c=F,prop.chisq=F)
```

compute percents (relative values) marginally:
```{r}
# severity by road surface condition:
CrossTable(accidents_EDA$Road_Surface_Conditions,accidents_EDA$Accident_Severity,prop.t=F, prop.r=T, prop.c=F,prop.chisq=F)
```
```{r}
# road surface condition by severity:
CrossTable(accidents_EDA$Road_Surface_Conditions,accidents_EDA$Accident_Severity,prop.t=F, prop.r=F, prop.c=T,prop.chisq=F)
```

I think the data on "Snow","Frost or ice","Flood over 3cm. deep" is too few to draw some conclusion, but we can see there's slightly higher portion of Serious accidents on Wet or damp roads than on Dry road.
Let's test the Ho that the variables are independent (not associated/different in portion of accident severity):
```{r}
CrossTable(accidents_EDA$Road_Surface_Conditions,accidents_EDA$Accident_Severity,prop.t=F, prop.r=F, prop.c=F,prop.chisq=F,chisq=T)
```
Chi-squared test reject the null hypothesis that there is no difference in accident severity with different road surface conditions.

Let's create the visual representation:
```{r}
legendPlot=levels(as.factor(unique(accidents_EDA$Accident_Severity)))
bartable = table(accidents_EDA$Accident_Severity,accidents_EDA$Road_Surface_Conditions)  ## get the cross tab
barplot(bartable, beside = TRUE,legend=legendPlot)  ## plot
```

represent the cross table in a nicer way:
```{r}
#turn table into a data frame:
accidents_EDA_Tb=as.data.frame(table(accidents_EDA$Accident_Severity,accidents_EDA$Road_Surface_Conditions))
names(accidents_EDA_Tb)=c('Accident_Severity','Road_Surface_Conditions','freq')

#Plot the Data
accidents_EDA_Tb%>%
  ggplot(aes(Accident_Severity,Road_Surface_Conditions )) + theme_bw()+ #white background
  geom_point(aes(size = freq), colour = "green")+ #green dot sized by frequency
  geom_text(aes(label = freq))+ # frequency value as label
  theme(legend.position="none")+ # no legend
  scale_size_continuous(range=c(5,30))+ # limits of point size
  labs(title="You see association?") # with titles!
```

## What attributes may increase the chance that an accident is serious (rather than slight)? (Logistic Regression)
I only want to know how the attributes affect the probability increase from slight to serious, so I need to drop those fatal incidents:
```{r}
accidents_reg=select(accidents,Accident_Index,Accident_Severity)
accidents_reg=accidents_reg[accidents_reg$Accident_Severity!=1,]
```
And re-code 0 as Serious, 1 as Slight.
```{r}
accidents_reg$Accident_Severity=accidents_reg$Accident_Severity-2
accidents_reg$Accident_Severity=as.factor(accidents_reg$Accident_Severity)
```
Check the dependent variable (accident severity) is dichotomous.
```{r}
barplot(table(accidents_reg$Accident_Severity))
```
In logistic regression, we have only two values, 0 and 1 ('Serious' and 'Slight') in Y. Then, the model will instead help you see which of the X variables will increase the 'odds' of getting a 1 ('Slight').

Some data cleaning and formatting before regression:
```{r}
vehicle_reg=select(vehicle,Accident_Index,Sex_of_Driver,Age_of_Driver,Age_of_Vehicle)
vehicle_reg=vehicle_reg[vehicle_reg$Sex_of_Driver%in%c(1,2)&vehicle_reg$Age_of_Driver!=-1&vehicle_reg$Age_of_Vehicle!=-1,] #include only Male and Female and valid age
vehicle_reg$Sex_of_Driver=vehicle_reg$Sex_of_Driver-1 #recode Male as 0, Female as 1
```

I averaged Sex of Driver, Age of Driver, Age of Vehicle. I think it's easy to understand why I chose last 2 variables. The logic behind average Sex of Driver lay on how I code them. As you see above, I code Male as 0, Female as 1. Thus, if the average Sex of Driver is close to 1, that means there are more female drivers, and vice versa.
```{r}
accidents_sex=aggregate(list(Avg_Sex_of_Driver=vehicle_reg$Sex_of_Driver),list(Accident_Index=vehicle_reg$Accident_Index),mean)
accidents_driverAge=aggregate(list(Avg_Age_of_Driver=vehicle_reg$Age_of_Driver),list(Accident_Index=vehicle_reg$Accident_Index),mean)
accidents_vehicleAge=aggregate(list(Avg_Age_of_Vehicle=vehicle_reg$Age_of_Vehicle),list(Accident_Index=vehicle_reg$Accident_Index),mean)
```

Merge all the dependent and independent variables into 1 data-frame.
```{r}
accidents_reg=merge(accidents_reg,accidents_sex)
merge=merge(accidents_driverAge,accidents_vehicleAge)
accidents_reg=merge(accidents_reg,merge)
```

The way to request this model is very similar to linear regression:
```{r}
# function 'glm' !
LogitSev_a =glm(Accident_Severity ~ Avg_Sex_of_Driver + Avg_Age_of_Driver + Avg_Age_of_Vehicle, 
                   data = accidents_reg,
                   family = binomial())

# see full results: summary(LogitSev_a)

# see relevant info on coefficients:
results_a=coef(summary(LogitSev_a))
data.frame(CoefficientExp=exp(results_a[,1]),Significant=results_a[,4]<0.05)
```

Instead of the Adjusted R Squared, the GLM function offers the Akaike Information Criterion (AIC) as a relative measure of fitness. If you had two models, the smaller the AIC signals the best one of the two compared. Let's make another model:
```{r}
# remember that presscat is factor
LogitSev_b=glm(Accident_Severity ~ Avg_Sex_of_Driver,data = accidents_reg,
                   family = binomial())
results_b=coef(summary(LogitSev_b))
data.frame(CoefficientExp=exp(results_b[,1]),Significant=results_b[,4]<0.05)
```
Now use the AIC:
```{r}
if (LogitSev_a$aic < LogitSev_b$aic){
    print("model 'a' is better")
}else{print("model 'b' is better")}
```

In mapping, I want to code the accident severity differently from above. Because they coded 1 as Fatal, 3 as Slight, I want them to be reversed to reflect common sense (higher score means more dangerous).
```{r message=FALSE, warning=FALSE}
library(psych)
accidents_map$Accident_Severity=reverse.code(-1,accidents_map$Accident_Severity)
```

Because one has to be 17 or above to legally drive in UK, I sum the population whose age is 17 or above.
```{r}
popabove17<-as.data.frame(apply(pop[,c(21:94)],1,sum))
popabove17<-transmute(popabove17,Code=pop$Code,Name=pop$Name,Pop=apply(pop[,c(21:94)],1,sum))
```

### Getting the Map
Get the map from GitHub:
```{r}
compressedMap = "https://github.com/daiyang94815/Road-Safety-UK-2016/raw/master/data/Local_Authority_Districts_December_2016_Full_Clipped_Boundaries_in_Great_Britain.zip"
```

```{r}
library(utils)
temp=tempfile()
download.file(compressedMap, temp)
unzip(temp)
```
To know what shapefiles are now in your directory:
```{r}
(maps=list.files(pattern = 'shp'))
```
You select which map from the object maps you need:
```{r}
library(rgdal)
GBMap <- rgdal::readOGR("Local_Authority_Districts_December_2016_Full_Clipped_Boundaries_in_Great_Britain.shp",stringsAsFactors=F) # use name
```
Now that you have a map, you can use common commands and see what you have:
```{r}
names(GBMap)
```
The Local Authority Districts (LAD) are coded as numbers in the dataset. I want to assign them the names according to the guide.
```{r}
accidents_map=merge(accidents_map,guide_lad,by.x='Local_Authority_.District.',by.y='code',all.x=T)
accidents_map=rename(accidents_map,lab_lad=label)
```
I want to know which LADs are dangerous (have higher total accident severity score). So I aggregate the accident severity to the LAD level. Remember how I code the accident severity, I reversed the original code, so now 1 is Slight, 2 is Serious, and 3 is Fatal. And the aggregation of these value is a rough estimation (accident severity score) of how dangerous a LAD is. This contains a implicit (and not necessarily right) assumption that a fatal accident is 2 times more dangerous than a slight one.
```{r}
accidents_lad=aggregate(accidents_map$Accident_Severity,list(accidents_map$lab_lad),sum)
names(accidents_lad)=c('Local_Authority_.District.','Accident_Severity_Score')
```
Then I merge the accident date and population data, then send it to the map
```{r}
accidentsGBmap=merge(GBMap,accidents_lad, by.x='lad16nm', by.y='Local_Authority_.District.',all=T)
accidentsGBmap=merge(accidentsGBmap,popabove17, by.x='lad16nm', by.y='Name',all=T)
```
Total accident severity is not good, so I calculate the ratio (severity to population).
```{r}
accidentsGBmap$AcciDen=accidentsGBmap$Accident_Severity_Score/accidentsGBmap$Pop
```
Let's explore the ratio in each LAD:
```{r}
summary(accidentsGBmap$AcciDen)
```
We got 8 NAs,
```{r}
# notice the use of '@data'
#finding the issue:
accidentsGBmap@data[is.na(accidentsGBmap$AcciDen),]['AcciDen']
```
We need to get rid of those rows:
```{r}
accidentsGBmap=accidentsGBmap[!is.na(accidentsGBmap$AcciDen),]
```
That has solved the problem:
```{r}
summary(accidentsGBmap$AcciDen)
```
We will plot the new variable asking for 5 quantiles. Let's follow these steps:
1.Install and load the necessary packages to manage color and divisions:
```{r}
library(RColorBrewer)
library(classInt)
```
2.Define the input:
```{r}
varToPLot=accidentsGBmap$AcciDen
```
3.Get colors and intervals (you can choose palettes from here):
```{r}
numberOfClasses = 3
colorForScale='YlGnBu'
colors = brewer.pal(numberOfClasses, colorForScale)
intervals <- classIntervals(varToPLot, numberOfClasses, 
                            style = "quantile",
                            dataPrecision=5)
colorPallette <- findColours(intervals, colors)
```
4.Plot
```{r}
legendText="Accident Severity Rate"
shrinkLegend=0.5
title="Accident Severity Rate in UK 2016"

plot(accidentsGBmap, col = colorPallette,border='grey',main=title,add=F)

legend('topright', legend = names(attr(colorPallette, "table")), 
       fill = attr(colorPallette, "palette"), cex = shrinkLegend, 
       bty = "n",
       title=legendText)
```
